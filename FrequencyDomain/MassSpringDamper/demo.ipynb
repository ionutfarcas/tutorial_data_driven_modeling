{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass-Spring-Damper System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first example for frequency domain modeling methods, we consider a classical mechanical mass-spring-damper system with a single chain of masses connected by springs and independent dampers on every mass. This system with $k$ masses can be described by second-order generalized differential equations of the form\n",
    "\n",
    "$$\n",
    "\\tag{4.1}\n",
    "\\begin{aligned}\n",
    "    m_{1} \\ddot{p}_{1}(t) + \\gamma_{1} \\dot{p}_{1}(t) + \\kappa_{1}(p_{1}(t) - p_{2}(t))\n",
    "    &= u(t),\n",
    "    \\\\\n",
    "    m_{i} \\ddot{p}_{i}(t) + \\gamma_{i} \\dot{p}_{i}(t) + \\kappa_{i} (p_{i}(t) - p_{i + 1}(t)) - \\kappa_{i-1} (p_{i - 1}(t) - p_{i}(t))\n",
    "    &= 0 \\quad \\text{for}~~i = 1, \\ldots, k - 1,\n",
    "    \\\\\n",
    "    m_{k} \\ddot{p}_{k}(t) + \\gamma_{k} \\dot{p}_{k}(t) + \\kappa_{p} p_{k}(t) - \\kappa_{k-1} (p_{k - 1}(t) - p_{k}(t))\n",
    "    &= 0,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "with mass, damping, and spring stiffness parameters $m_{i}, \\gamma_{i}, \\kappa_{i} > 0,$ for $i = 1, \\ldots, k$.\n",
    "The external forcing $u(t)$ acts only on the first mass.\n",
    "The quantity of interest is the velocity of the first mass in the chain,\n",
    "\n",
    "$$\n",
    "    y(t) = \\dot{p}_{1}(t).\n",
    "$$\n",
    "\n",
    "Using the extended state\n",
    "\n",
    "$$\n",
    "    \\mathbf{q}(t) = \\begin{bmatrix}\n",
    "        p_1(t) \\\\ \\vdots \\\\ p_k(t)\n",
    "        \\\\\n",
    "        \\dot{p}_1(t) \\\\ \\vdots \\\\ \\dot{p}_k(t)\n",
    "    \\end{bmatrix} \\in \\mathbb{R}^{2k},\n",
    "$$\n",
    "\n",
    "the dynamical system $(4.1)$ can be written in the classical linear form\n",
    "\n",
    "$$\n",
    "\\tag{4.2}\n",
    "\\begin{aligned}\n",
    "    \\mathbf{E} \\dot{\\mathbf{q}}(t)\n",
    "    &= \\mathbf{A} \\mathbf{q}(t) + \\mathbf{b} u(t),\n",
    "    \\\\\n",
    "    y(t)\n",
    "    &= \\mathbf{c}^\\mathsf{T} \\mathbf{q}(t)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{E},\\mathbf{A}\\in\\mathbb{R}^{n\\times n}$ and $\\mathbf{b},\\mathbf{c}\\in\\mathbb{R}^{n}$ with $n = 2k$.\n",
    "Because the input $u(t)$ and the output $y(t)$ are both one-dimensional, this is a *single-input single-output* (SISO) system.\n",
    "\n",
    "The *transfer function* corresponding to $(4.2)$ is given by\n",
    "\n",
    "$$\n",
    "\\tag{4.3}\n",
    "\\begin{aligned}\n",
    "    G(s) = \\mathbf{c}^\\mathsf{T} (s \\mathbf{E} - \\mathbf{A})^{-1} \\mathbf{b},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "which satisfies $Y(s) = G(s)U(s)$ where $U(s)$ and $Y(s)$ are the Laplace transforms of $u(t)$ and $y(t),$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For given measurements of the transfer function $G(s),$ our objective is to find potentially low-dimensional matrices $\\widehat{\\mathbf{A}},$ $\\widehat{\\mathbf{b}},$ $\\widehat{\\mathbf{c}},$ and $\\widehat{\\mathbf{E}}$ so that the corresponding transfer function\n",
    "\n",
    "$$\n",
    "\\widehat{G}(s)\n",
    "= \\widehat{\\mathbf{c}}^\\mathsf{T} (s \\widehat{\\mathbf{E}} - \\widehat{\\mathbf{A}})^{-1} \\widehat{\\mathbf{b}}\n",
    "$$\n",
    "\n",
    "approximates the given data well.\n",
    "Since the matrix system structure is retained, the matrices $\\widehat{\\mathbf{A}},$ $\\widehat{\\mathbf{b}},$ $\\widehat{\\mathbf{c}},$ and $\\widehat{\\mathbf{E}}$ can be viewed as taking the role of the system matrices $\\mathbf{A},$ $\\mathbf{b},$ $\\mathbf{c},$ and $\\mathbf{E}$, respectively, in the time-domain description of the system.\n",
    "\n",
    "**Note**: This data fitting problem is a *rational approximation* problem, so named because the transfer function to be constructed is a rational function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some standard Python packages for our computations and the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse as sparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System construction and some visualization routines are implemented in the file [utils.py](./utils.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "utils.configure_matplotlib(latex_is_installed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file also defines two important classes that we will use:\n",
    "\n",
    "- The `SISO` class represents general linear systems of the form $(4.2)$.\n",
    "- The `MassSpringDamper` class constructs the particular SISO system $(4.1)$.\n",
    "\n",
    "Both classes have `A`, `b`, `c`, and `E` attributes representing the system matrices, as well as a simple `transfer_function()` method for evaluating $(4.3)$ which boils down to the following line.\n",
    "\n",
    "```python\n",
    "    response = c @ scipy.linalg.solve(s * E - A, b)\n",
    "```\n",
    "\n",
    "To begin, we generate a mass-spring-damper system with just $2$ masses (hence $4$ degrees of freedom) and some standard parameters. Later in this demonstration, we will consider the high-dimensional case in which dimensionality reduction plays a role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_model = utils.MassSpringDamper(\n",
    "    num_masses = 2, mass = 1.0, damping = 0.1, stiffness = 10.0\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"State matrix A:\",\n",
    "    truth_model.A.toarray(),\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "\n",
    "print(truth_model.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathfrak{j} = \\sqrt{-1}$ be the imaginary unit, in Python given by `1j`. The next block plots the magnitude of transfer function values, $|G(\\mathrm{j}\\omega)|,$ for $500$ logarithmically spaced frequencies $\\omega$ in the interval $[10^{-2}, 10^{2}]$ rad/s. We call the transfer function values the *frequency response* of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = np.logspace(-2, 2, 500)\n",
    "responses   = truth_model.transfer_function(1j * frequencies)\n",
    "\n",
    "utils.plot_response(frequencies, responses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents the function that we are aiming to approximate via frequency domain data using the Loewner framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn a dynamical system from a limited number of transfer function samples. Due to the amount of degrees of freedom when designing systems with the Loewner framework, we need an **even** number of data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data samples generated (this must be an even integer).\n",
    "num_samples = 8\n",
    "\n",
    "# Sample the transfer function.\n",
    "training_frequencies = np.logspace(-2, 2, num_samples)\n",
    "training_responses   = truth_model.transfer_function(1j * training_frequencies)\n",
    "\n",
    "# Plot the data samples over the actual transfer function.\n",
    "ax = utils.plot_response(\n",
    "    frequencies,\n",
    "    responses,\n",
    "    label = \"Transfer function\"\n",
    ")\n",
    "ax.loglog(\n",
    "    training_frequencies,\n",
    "    np.abs(training_responses),  # Responses are complex, so plot magnitude.\n",
    "    \"ks\",\n",
    "    label = \"Samples\"\n",
    ")\n",
    "ax.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In this example, exactly $8$ data samples are needed to construct a highly accuracy model, since there are $n = 4$ degrees of freedom and the samples are split into two even groups of $4$ (detailed explanation follows below). Try experimenting with fewer samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Construct Loewner matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Loewner framework builds a system whose transfer function, by construction, interpolates the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Left and Right Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\omega_1, \\omega_2, \\ldots$ denote the training frequencies and define the interpolation points $\\mu_i = \\mathfrak{j}\\omega_i$.\n",
    "The goal is to construct $\\widehat{G}:\\mathbb{C}\\to\\mathbb{C}$ so that $\\widehat{G}(\\mu_i) = G(\\mu_i)$ for all $i$.\n",
    "\n",
    "First, we split the data pairs $\\{(\\mu_i, G(\\mu_i))\\}_i$ into two subsets of equal size of the form $(\\mu_{\\operatorname{\\ell}}, g_{\\operatorname{\\ell}})$ and $(\\mu_{\\operatorname{r}}, g_{\\operatorname{r}})$. These are referred to as left and right datasets. While the distribution of data does not play any theoretical role, we select alternating data points from the full set of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left data pairs.\n",
    "w_l  = training_frequencies[0::2]\n",
    "g_l  = training_responses[0::2]\n",
    "mu_l = 1j * w_l\n",
    "\n",
    "# Right data pairs.\n",
    "w_r  = training_frequencies[1::2]\n",
    "g_r  = training_responses[1::2]\n",
    "mu_r = 1j * w_r\n",
    "\n",
    "# Plot the data samples over the actual transfer function.\n",
    "ax = utils.plot_response(frequencies, responses, label = \"Transfer function\")\n",
    "utils.plot_samples(w_l, g_l, w_r, g_r, ax = ax)\n",
    "ax.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Loewner Matrices and the Corresponding System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Loewner ROM is defined in terms of the matrices\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbb{L}\n",
    "    &= \\begin{bmatrix}\n",
    "        \\frac{g_{\\operatorname{\\ell}, 1} - g_{\\operatorname{r}, 1}}{\\mu_{\\operatorname{\\ell}, 1} - \\mu_{\\operatorname{r}, 1}} & \\frac{g_{\\operatorname{\\ell}, 1} - g_{\\operatorname{r}, 2}}{\\mu_{\\operatorname{\\ell}, 1} - \\mu_{\\operatorname{r}, 2}} & \\cdots\n",
    "        \\\\[.25cm]\n",
    "        \\frac{g_{\\operatorname{\\ell}, 2} - g_{\\operatorname{r}, 1}}{\\mu_{\\operatorname{\\ell}, 2} - \\mu_{\\operatorname{r}, 1}} & \\frac{g_{\\operatorname{\\ell}, 2} - g_{\\operatorname{r}, 2}}{\\mu_{\\operatorname{\\ell}, 2} - \\mu_{\\operatorname{r}, 2}} &  \\cdots\n",
    "        \\\\[.25cm]\n",
    "        \\vdots & \\vdots & \\ddots\n",
    "    \\end{bmatrix} \\in \\mathbb{C}^{kp \\times km},\n",
    "    &\n",
    "    \\mathbb{L}_{\\operatorname{s}} &= \\begin{bmatrix}\n",
    "        \\frac{\\mu_{\\operatorname{\\ell}, 1}g_{\\operatorname{\\ell}, 1} - \\mu_{\\operatorname{r}, 1}g_{\\operatorname{r}, 1}}{\\mu_{\\operatorname{\\ell}, 1} - \\mu_{\\operatorname{r}, 1}} & \\frac{\\mu_{\\operatorname{\\ell}, 1}g_{\\operatorname{\\ell}, 1} - \\mu_{\\operatorname{r}, 2}g_{\\operatorname{r}, 2}}{\\mu_{\\operatorname{\\ell}, 1} - \\mu_{\\operatorname{r}, 2}} & \\cdots\n",
    "        \\\\[.25cm]\n",
    "        \\frac{\\mu_{\\operatorname{\\ell}, 2}g_{\\operatorname{\\ell}, 2} - \\mu_{\\operatorname{r}, 1}g_{\\operatorname{r}, 1}}{\\mu_{\\operatorname{\\ell}, 2} - \\mu_{\\operatorname{r}, 1}} & \\frac{\\mu_{\\operatorname{\\ell}, 2} g_{\\operatorname{\\ell}, 2} - \\mu_{\\operatorname{r}, 2} g_{\\operatorname{r}, 2}}{\\mu_{\\operatorname{\\ell}, 2} - \\mu_{\\operatorname{r}, 2}} &  \\cdots\n",
    "        \\\\[.25cm]\n",
    "        \\vdots & \\vdots & \\ddots\n",
    "    \\end{bmatrix} \\in \\mathbb{C}^{kp \\times km},\n",
    "    \\\\\n",
    "    \\mathbf{B}_{\\mathbb{L}}\n",
    "    &= \\begin{bmatrix}\n",
    "        g_{\\operatorname{\\ell}, 1} \\\\\n",
    "        g_{\\operatorname{\\ell}, 2} \\\\\n",
    "        \\vdots\n",
    "    \\end{bmatrix} \\in \\mathbb{C}^{kp \\times m},\n",
    "    &\n",
    "    \\mathbf{C}_{\\mathbb{L}}\n",
    "    &= \\left[\\begin{array}{ccc}\n",
    "        g_{\\operatorname{r}, 1} & g_{\\operatorname{r}, 2} & \\cdots\n",
    "    \\end{array}\\right] \\in \\mathbb{C}^{p \\times km},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "using the separated data sets $(\\mu_{\\operatorname{\\ell}}, g_{\\operatorname{\\ell}})$ and $(\\mu_{\\operatorname{r}}, g_{\\operatorname{r}})$ of lengths $k$.\n",
    "Here, $m$ and $p$ are the numbers of inputs and outputs to the system, respectively; in this single-input single-output problem, $m = p = 1$.\n",
    "In general, we call $\\mathbb{L}$ a *Loewner matrix* and $\\mathbb{L}_{\\operatorname{s}}$ a *shifted Loewner matrix*.\n",
    "\n",
    "The system whose transfer function interpolates the data is then defined by the matrices\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\widehat{\\mathbf{A}}\n",
    "    &= -\\mathbb{L}_{\\operatorname{s}}\n",
    "    &\n",
    "    \\widehat{\\mathbf{b}}\n",
    "    &= \\mathbf{B}_{\\mathbb{L}},\n",
    "    &\n",
    "    \\widehat{\\mathbf{c}}\n",
    "    &= \\mathbf{C}_{\\mathbb{L}},\n",
    "    &\n",
    "    \\widehat{\\mathbf{E}} &= -\\mathbb{L}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Note**: This is system identification, not model reduction, as there is no dimensionality reduction (yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loewner_matrices(mu_l, g_l, mu_r, g_r):\n",
    "    \"\"\"Construct the Loewner matrices L, Ls, BL, and CL.\"\"\"\n",
    "    BL = g_l\n",
    "    CL = g_r\n",
    "\n",
    "    k  = len(mu_l)\n",
    "    L  = np.zeros((k, k), dtype = complex)\n",
    "    Ls = np.zeros((k, k), dtype = complex)\n",
    "\n",
    "    # Explicit entrywise construction.\n",
    "    # for i in range(k):\n",
    "    #     for j in range(k):\n",
    "    #         L[i, j] = (g_l[i] - g_r[j]) / (mu_l[i] - mu_r[j])\n",
    "    #         Ls[i, j] = (mu_l[i] * g_l[i] - mu_r[j] * g_r[j]) / (mu_l[i] - mu_r[j])\n",
    "\n",
    "    # Array broadcasting construction.\n",
    "    g_l  = g_l.reshape((k, 1))  # Make these into column vectors.\n",
    "    mu_l = mu_l.reshape((k, 1))\n",
    "\n",
    "    L  = (g_l - g_r) / (mu_l - mu_r)\n",
    "    Ls = ((mu_l * g_l) - (mu_r * g_r)) / (mu_l - mu_r)\n",
    "\n",
    "    return L, Ls, BL, CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, Ls, BL, CL = loewner_matrices(mu_l, g_l, mu_r, g_r)\n",
    "\n",
    "loewner_model = utils.SISO(A = -Ls, b = BL, c = CL, E = -L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate the Learned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy in this setting is evaluated by checking the transfer function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check: Compare to Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we compare the frequency response of the learned model at the training frequencies.\n",
    "These should match up to machine precision because this method is interpolatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_reponses = loewner_model.transfer_function(\n",
    "    1j * training_frequencies\n",
    ")\n",
    "\n",
    "for w, g_true, g_model in zip(\n",
    "    training_frequencies, training_responses, model_training_reponses\n",
    "):\n",
    "    print(\n",
    "        f\"Frequency: {w:.4e}\",\n",
    "        f\"Truth: {g_true.real: >10.3e} + {g_true.imag: >10.3e}j\",\n",
    "        f\"Loewner: {g_model.real: >10.3e} + {g_model.imag: >10.3e}j\",\n",
    "        sep=\"    \",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict at Non-Training Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can also have a look at the pointwise relative error for general frequencies,\n",
    "\n",
    "$$\n",
    "\\operatorname{relerr}(\\omega) = \\frac{\\lvert G(\\mathfrak{j} \\omega) - \\widehat{G}(\\mathfrak{j} \\omega) \\rvert}{\\lvert G(\\mathfrak{j} \\omega) \\rvert}.\n",
    "$$\n",
    "\n",
    "The following code block compares the transfer function of the learned model to that of the truth model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the transfer function of the learned model at many frequencies.\n",
    "model_responses = loewner_model.transfer_function(1j * frequencies)\n",
    "\n",
    "# Calculate the relative error based on the true frequency reponses.\n",
    "model_relative_errors = np.abs(model_responses - responses) / np.abs(responses)\n",
    "\n",
    "# Visualize the results.\n",
    "utils.plot_comparison(\n",
    "    frequencies,\n",
    "    responses,\n",
    "    model_responses,\n",
    "    model_relative_errors,\n",
    "    w_l,\n",
    "    g_l,\n",
    "    w_r,\n",
    "    g_r,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If the true $\\mathbf{A},$ $\\mathbf{b},$ $\\mathbf{c},$ and $\\mathbf{E}$ are available, a SISO system can be constructed that produces the (absolute) error by\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    G(s) - \\widehat{G}(s)\n",
    "    = \\begin{bmatrix}\n",
    "        \\mathbf{c} \\\\ -\\widehat{\\mathbf{c}}\n",
    "    \\end{bmatrix}^\\mathsf{T}\n",
    "    \\left(s \\begin{bmatrix}\n",
    "        \\mathbf{E} & 0 \\\\ 0 & \\widehat{\\mathbf{E}}\n",
    "    \\end{bmatrix} - \\begin{bmatrix}\n",
    "        \\mathbf{A} & 0 \\\\ 0 & \\widehat{\\mathbf{A}}\n",
    "    \\end{bmatrix} \\right)^{-1}\n",
    "    \\begin{bmatrix} \\mathbf{b} \\\\ \\widehat{\\mathbf{b}} \\end{bmatrix}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the error system.\n",
    "error_model = utils.SISO(\n",
    "    A = sparse.block_diag((truth_model.A, loewner_model.A)),  # [A, 0; 0, Ahat]\n",
    "    b = np.concatenate((truth_model.b, loewner_model.b)),  # [b; bhat]\n",
    "    c = np.concatenate((truth_model.c, -loewner_model.c)),  # [c; -chat]\n",
    "    E = sparse.block_diag((truth_model.E, loewner_model.E)),  # [E, 0; 0, Ehat]\n",
    ")\n",
    "\n",
    "# Evaluate the error system transfer function, which gives the absolute error.\n",
    "error_model_response = error_model.transfer_function(1j * frequencies)\n",
    "\n",
    "# Compare the (relative) error to the previous computation.\n",
    "np.allclose(error_model_response / np.abs(responses), model_relative_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Even though the response of the learned system matches the true system response up to machine precision, the learned matrices $\\widehat{\\mathbf{A}},$ $\\widehat{\\mathbf{b}},$ $\\widehat{\\mathbf{c}},$ and $\\widehat{\\mathbf{E}}$ are not necessarily equal to the original $\\mathbf{A},$ $\\mathbf{b},$ $\\mathbf{c},$ and $\\mathbf{E}$. However, they are equivalent and can be related by a state-space transformation, meaning there exist invertible matrices $\\mathbf{W},\\mathbf{T}\\in\\mathbb{C}^{n\\times n}$ such that\n",
    "\n",
    "$$\n",
    "    \\mathbf{A} = \\mathbf{W} \\widehat{\\mathbf{A}} \\mathbf{T},\n",
    "    \\quad\n",
    "    \\mathbf{b} = \\mathbf{W} \\widehat{\\mathbf{b}},\n",
    "    \\quad\n",
    "    \\mathbf{c} = \\widehat{\\mathbf{c}} \\mathbf{T},\n",
    "    \\quad\n",
    "    \\mathbf{E} = \\mathbf{W} \\widehat{\\mathbf{E}} \\mathbf{T}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Shape of   truth model A: {truth_model.A.shape}\",\n",
    "    f\"Shape of learned model A: {loewner_model.A.shape}\",\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "\n",
    "# The state matrices are not the same.\n",
    "# (This will raise an error if num_samples != 8.)\n",
    "print(\n",
    "    \"\\nA matrices are the same:\",\n",
    "    np.allclose(truth_model.A.toarray(), loewner_model.A),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension 1: More Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Loewner framework constructs an interpolating system whose dimension is half the number of data samples, which is why using $8$ samples results in interpolation when the truth model has dimension $n = 2k = 4$. When more data samples are available, the Loewner model is overfitting and an adjustment is needed. First, observe that the rank of the Loewner pencil matrices\n",
    "\n",
    "$$\n",
    "    r\n",
    "    = \\operatorname{rank}\\left(\\begin{bmatrix}\n",
    "        \\mathbb{L}_{\\operatorname{s}} \\\\ \\mathbb{L}\n",
    "    \\end{bmatrix}\\right)\n",
    "    = \\operatorname{rank}\\left(\\begin{bmatrix}\n",
    "        \\mathbb{L}_{\\operatorname{s}} & \\mathbb{L}\n",
    "    \\end{bmatrix}\\right)\n",
    "$$\n",
    "\n",
    "corresponds to the system rank in the sense that $r \\leq n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = la.svdvals(np.vstack((L, Ls)))  # [L; Ls]\n",
    "s2 = la.svdvals(np.hstack((L, Ls)))  # [L, Ls]\n",
    "\n",
    "utils.plot_singular_values(s1, s2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These pencils have rank $r = 4,$ which is exactly the dimension of the original system.\n",
    "If we have $n_s = 12 > 2n$ data samples, the Loewner model constructs a linear system of dimension $r = n_s / 2 = 6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 12\n",
    "\n",
    "# Sample the transfer function.\n",
    "training_frequencies = np.logspace(-2, 2, num_samples)\n",
    "training_responses   = truth_model.transfer_function(1j * training_frequencies)\n",
    "\n",
    "# Left data pairs.\n",
    "w_l  = training_frequencies[0::2]\n",
    "g_l  = training_responses[0::2]\n",
    "mu_l = 1j * w_l\n",
    "\n",
    "# Right data pairs.\n",
    "w_r  = training_frequencies[1::2]\n",
    "g_r  = training_responses[1::2]\n",
    "mu_r = 1j * w_r\n",
    "\n",
    "# Construct Loewner matrices.\n",
    "L, Ls, BL, CL = loewner_matrices(mu_l, g_l, mu_r, g_r)\n",
    "\n",
    "# Compute the singular values of the pencil matrices.\n",
    "s1 = la.svdvals(np.vstack((L, Ls)))  # [L; Ls]\n",
    "s2 = la.svdvals(np.hstack((L, Ls)))  # [L, Ls]\n",
    "\n",
    "utils.plot_singular_values(s1, s2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank of the Loewner pencils is still $r = 4,$ with larger singular values being numerically zero. Using these matrices would result in a singular system, i.e., $s\\widehat{\\mathbf{E}} - \\widehat{\\mathbf{A}}$ is not invertible for any $s \\in \\mathbb{C}$. To recover an $r = 4$ dimensional system, we use the singular value decompositions of the two concatenated matrices above,\n",
    "\n",
    "$$\n",
    "    \\boldsymbol{\\Phi}_1\\boldsymbol{\\Sigma}_1\\boldsymbol{\\Psi}_1^\\mathsf{H}\n",
    "    = \\begin{bmatrix} \\mathbb{L}_{\\operatorname{s}} \\\\ \\mathbb{L} \\end{bmatrix}\n",
    "    \\quad\\text{and}\\quad\n",
    "    \\boldsymbol{\\Phi}_2\\boldsymbol{\\Sigma}_2\\boldsymbol{\\Psi}_2^\\mathsf{H}\n",
    "    = \\begin{bmatrix} \\mathbb{L}_{\\operatorname{s}} & \\mathbb{L} \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The orthogonal bases of degree $r$ resulting from these decompositions can be used to truncate the Loewner matrices and construct the appropriate system:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\widehat{\\mathbf{A}}\n",
    "    &= - \\boldsymbol{\\Phi}_{2,r}^\\mathsf{H} \\mathbb{L}_{s} \\boldsymbol{\\Psi}_{1,r},\n",
    "    &\n",
    "    \\widehat{\\mathbf{b}}\n",
    "    &= \\boldsymbol{\\Phi}_{2,r}^\\mathsf{H} \\mathbf{B}_{\\mathbb{L}}\n",
    "    &\n",
    "    \\widehat{\\mathbf{c}}\n",
    "    &= \\mathbf{C}_{\\mathbb{L}}\\boldsymbol{\\Psi}_{1,r},\n",
    "    &\n",
    "    \\widehat{\\mathbf{E}}\n",
    "    &= - \\boldsymbol{\\Phi}_{2,r}^\\mathsf{H} \\mathbb{L} \\boldsymbol{\\Psi}_{1,r},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\Phi}_{2,r}$ comprises the first $r$ columns of $\\boldsymbol{\\Phi}_2$ and similar for $\\boldsymbol{\\Psi}_{1,r}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the SVDs of the Loewner pencil.\n",
    "Phi_1, s1, Psi_1T = la.svd(np.vstack((L, Ls)))\n",
    "Phi_2, s2, Psi_2T = la.svd(np.hstack((L, Ls)))\n",
    "\n",
    "# Determine the rank from the singular values.\n",
    "r = np.count_nonzero(s1 > s1[0] * 1.0e-12)\n",
    "print(f\"Numerical rank based on SVD: {r:d}\")\n",
    "\n",
    "# Construct the truncated system.\n",
    "Ar = -Phi_2[:, :r].conj().T @ (Ls @ Psi_1T[:r, :].conj().T)\n",
    "br = Phi_2[:, :r].conj().T @ g_l\n",
    "cr = g_r @ Psi_1T[:r, :].conj().T\n",
    "Er = -Phi_2[:, :r].conj().T @ (L @ Psi_1T[:r, :].conj().T)\n",
    "\n",
    "loewner_model2 = utils.SISO(A = Ar, b = br, c = cr, E = Er)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We correctly determined the rank to be $r = 4$ and constructed the corresponding Loewner system. Let's quickly check the results as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the transfer function of the learned model at many frequencies.\n",
    "model_responses2 = loewner_model2.transfer_function(1j * frequencies)\n",
    "\n",
    "# Calculate the relative error based on the true frequency reponses.\n",
    "model_relative_errors2 = np.abs(model_responses2 - responses) / np.abs(\n",
    "    responses\n",
    ")\n",
    "\n",
    "# Visualize the results.\n",
    "utils.plot_comparison(\n",
    "    frequencies,\n",
    "    responses,\n",
    "    model_responses2,\n",
    "    model_relative_errors2,\n",
    "    w_l,\n",
    "    g_l,\n",
    "    w_r,\n",
    "    g_r,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: This truncation approach can be used to construct reduced-order models with $r < n.$ We only need to determine a suitable $r,$ which is either chosen via a relative tolerance for the singular values of the Loewner pencil or via a maximum order set by the user. This is demonstrated at the end of this notebook. Note that if we truncate before the true pencil rank, i.e., choose $r$ with\n",
    "\n",
    "$$\n",
    "    r\n",
    "    < \\operatorname{rank}\\left(\\begin{bmatrix}\n",
    "        \\mathbb{L}_{\\operatorname{s}} \\\\ \\mathbb{L}\n",
    "    \\end{bmatrix}\\right)\n",
    "    = \\operatorname{rank}\\left(\\begin{bmatrix}\n",
    "        \\mathbb{L}_{\\operatorname{s}} & \\mathbb{L}\n",
    "    \\end{bmatrix}\\right),\n",
    "$$\n",
    "\n",
    "then the interpolation property of the Loewner framework is lost.\n",
    "Empirically, it has been observed that by using the singular value decomposition for the truncation process, the resulting system fits the data in an *approximate least-squares* sense instead of interpolating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension 2: Realification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned matrices $\\widehat{\\mathbf{A}},$ $\\widehat{\\mathbf{b}},$ $\\widehat{\\mathbf{c}},$ and $\\widehat{\\mathbf{E}}$ constructed so far are complex-valued, even though the original system matrices are all real-valued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"True state matrix A:\",\n",
    "    truth_model.A.toarray(),\n",
    "    \"\\nLoewner state matrix A:\",\n",
    "    loewner_model.A,\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many applications, we want to preserve the realness of the original system by enforcing realness of the learned matrices for any given data. To do this, we need the important observation that for a transfer function of a first-order system with real matrices, it holds that\n",
    "\n",
    "$$\n",
    "\\overline{G(s)} = G(\\overline{s}),\n",
    "$$\n",
    "\n",
    "which means that the transfer function values of complex conjugate evaluation points are also complex conjugates. The following code verifies this with our mass-spring-damper system example on four sets of complex conjugate points and the corresponding transfer function values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1j * np.logspace(-2, 2, num = 4)\n",
    "\n",
    "g1 = truth_model.transfer_function(s).conj()\n",
    "g2 = truth_model.transfer_function(s.conj())\n",
    "\n",
    "print(\n",
    "    f\"conj(G(s)):\\n{g1}\",\n",
    "    f\"G(conj(s)):\\n{g2}\",\n",
    "    f\"Numerically equal: {np.allclose(g1, g2)}\",\n",
    "    sep=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need this type of data to construct models with real matrices. As we typically do not have evaluations of transfer functions in the lower complex half-plane, we can artificially create the complex conjugate data from already given data. Once we have this, we need to split and reorder the data so that for the left and right data we have the complex conjugate data pairs in the same data set and interchanging, i.e.,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  \\mu_{\\operatorname{\\ell}} & = \\{ \\mu_{\\operatorname{\\ell}, 1}, \\overline{\\mu_{\\operatorname{\\ell}, 1}}, \\mu_{\\operatorname{\\ell}, 2}, \\overline{\\mu_{\\operatorname{\\ell}, 2}}, \\ldots  \\}, &\n",
    "  g_{\\operatorname{\\ell}} & = \\{ g_{\\operatorname{\\ell}, 1}, \\overline{g_{\\operatorname{\\ell}, 1}}, g_{\\operatorname{\\ell}, 2}, \\overline{g_{\\operatorname{\\ell}, 2}}, \\ldots \\}, \\\\\n",
    "  \\mu_{\\operatorname{r}} & = \\{ \\mu_{\\operatorname{r}, 1}, \\overline{u_{\\operatorname{r}, 1}}, u_{\\operatorname{r}, 2}, \\overline{u_{\\operatorname{r}, 2}}, \\ldots  \\}, &\n",
    "  g_{\\operatorname{r}} & = \\{ g_{\\operatorname{r}, 1}, \\overline{g_{\\operatorname{r}, 1}}, g_{\\operatorname{r}, 2}, \\overline{g_{\\operatorname{r}, 2}}, \\ldots \\}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_conjugates(arr):\n",
    "    \"\"\"From an array [x1, x2, ...], form [x1, conj(x1), x2, conj(x2), ...]\"\"\"\n",
    "    new_arr       = np.empty(len(arr) * 2, dtype = complex)\n",
    "    new_arr[::2]  = arr\n",
    "    new_arr[1::2] = arr.conj()\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we build the Loewner system with this data, there exists a state-space transformation that results in real system matrices. This transformation is given by\n",
    "\n",
    "$$\n",
    "    \\mathbf{J}\n",
    "    = \\mathbf{I}_{k} \\otimes \\frac{1}{\\sqrt{2}}\n",
    "    \\left[\\begin{array}{rr}\n",
    "        1 & \\mathrm{j} \\\\ 1 & -\\mathrm{j}\n",
    "    \\end{array}\\right],\n",
    "$$\n",
    "\n",
    "and then applied so that\n",
    "\n",
    "$$\n",
    "    \\widehat{\\mathbf{A}}\n",
    "    = -\\mathbf{J}^\\mathsf{H}\\mathbb{L}_{\\operatorname{s}} \\mathbf{J},\n",
    "    \\quad\n",
    "    \\widehat{\\mathbf{b}}\n",
    "    = \\mathbf{J}^\\mathsf{H} g_{\\operatorname{\\ell}},\n",
    "    \\quad\n",
    "    \\widehat{\\mathbf{c}}\n",
    "    = g_{\\operatorname{r}} \\mathbf{J},\n",
    "    \\quad\n",
    "    \\widehat{\\mathbf{E}} = -\\mathbf{J}^\\mathsf{H} \\mathbb{L} \\mathbf{J}.\n",
    "$$\n",
    "\n",
    "Let's do exactly that for our mass-spring damper example. We have already generated the necessary data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate only 4 samples (since conjugate data doubles the sample size).\n",
    "num_samples = 4\n",
    "\n",
    "# Sample the transfer function.\n",
    "training_frequencies = np.logspace(-2, 2, num_samples)\n",
    "training_responses   = truth_model.transfer_function(1j * training_frequencies)\n",
    "\n",
    "# Split into left and right data sets AND add in the conjugates.\n",
    "mu_l = insert_conjugates(1j * training_frequencies[::2])\n",
    "mu_r = insert_conjugates(1j * training_frequencies[1::2])\n",
    "g_l  = insert_conjugates(training_responses[::2])\n",
    "g_r  = insert_conjugates(training_responses[1::2])\n",
    "\n",
    "# Construct the transformation matrix J.\n",
    "J = sparse.kron(\n",
    "    sparse.eye(num_samples // 2),\n",
    "    sparse.coo_matrix((1 / np.sqrt(2)) * np.array([[1, 1j], [1, -1j]])),\n",
    ")\n",
    "\n",
    "# Construct Loewner matrices.\n",
    "L, Ls, BL, CL = loewner_matrices(mu_l, g_l, mu_r, g_r)\n",
    "\n",
    "# Transform the Loewner system to real coordinates.\n",
    "Ar = -J.conj().T @ (Ls @ J)\n",
    "br = J.conj().T @ g_l\n",
    "cr = g_r @ J\n",
    "Er = -J.conj().T @ (L @ J)\n",
    "\n",
    "# Check that the system matrices are real.\n",
    "for label, arr in zip(\"AbcE\", [Ar, br, cr, Er]):\n",
    "    print(\n",
    "        f\"{arr.shape} matrix '{label}' has all real entries:\",\n",
    "        np.allclose(arr.real, arr),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can check that our the resulting system is actually correct, by computing its transfer function and printing the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loewner_model3 = utils.SISO(A = Ar, b = br, c = cr, E = Er)\n",
    "\n",
    "# Evaluate the transfer function of the learned model at many frequencies.\n",
    "model_responses3 = loewner_model3.transfer_function(1j * frequencies)\n",
    "\n",
    "# Calculate the relative error based on the true frequency reponses.\n",
    "model_relative_errors3 = np.abs(model_responses2 - responses) / np.abs(\n",
    "    responses\n",
    ")\n",
    "\n",
    "# Visualize the results.\n",
    "utils.plot_comparison(\n",
    "    frequencies,\n",
    "    responses,\n",
    "    model_responses3,\n",
    "    model_relative_errors3,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: The Complete and Practical Loewner Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the components together, it is finally time to apply the truncated Loewner framework with realification to a large data set. As example, we increase the size of the mass-spring-damper system to a chain with $k = 1000$ masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_model = utils.MassSpringDamper(\n",
    "    num_masses = 1000, mass = 1.0, damping = 0.1, stiffness = 10.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe data for $300$ frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 300\n",
    "\n",
    "training_frequencies = np.logspace(-2, 2, num_samples)\n",
    "training_responses   = large_model.transfer_function(1j * training_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we repeat the same steps from before, combining the two extensions:\n",
    "\n",
    "1. Split the data and add the complex conjugates to allow for realification.\n",
    "\n",
    "2. Construct the Loewner matrices.\n",
    "\n",
    "3. Transform the Loewner matrices from complex to real entries.\n",
    "\n",
    "4. Determine a suitable truncation rank.\n",
    "\n",
    "5. Truncate the Loewner system to a real-valued low-dimensional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into left and right data sets AND add in the conjugates.\n",
    "mu_l = insert_conjugates(1j * training_frequencies[::2])\n",
    "mu_r = insert_conjugates(1j * training_frequencies[1::2])\n",
    "g_l  = insert_conjugates(training_responses[::2])\n",
    "g_r  = insert_conjugates(training_responses[1::2])\n",
    "\n",
    "# Construct the transformation matrix J.\n",
    "J = sparse.kron(\n",
    "    sparse.eye(num_samples // 2),\n",
    "    sparse.coo_matrix((1 / np.sqrt(2)) * np.array([[1, 1j], [1, -1j]])),\n",
    ")\n",
    "\n",
    "# Construct Loewner matrices.\n",
    "L, Ls, BL, CL = loewner_matrices(mu_l, g_l, mu_r, g_r)\n",
    "\n",
    "# Transform the Loewner system to real coordinates.\n",
    "AL = -J.conj().T @ (Ls @ J)\n",
    "bL = J.conj().T @ g_l\n",
    "cL = g_r @ J\n",
    "EL = -J.conj().T @ (L @ J)\n",
    "\n",
    "# Compute the singular value decompositions of the pencil matrices.\n",
    "Phi_1, s1, Psi_1T = la.svd(np.vstack((EL, AL)))  # [-L; -Ls]\n",
    "Phi_2, s2, Psi_2T = la.svd(np.hstack((EL, AL)))  # [-L, -Ls]\n",
    "\n",
    "# Visualization singular value decay to determine rank.\n",
    "utils.plot_singular_values(s1, s2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given data has a very steep singular value decay, so we can expect that a low-dimensional model will be sufficient to approximate the data well. Here, we use a relative tolerance of $10^{-6}$ on the singular values of the Loewner pencil to select the reduced dimension $r$. Experiment with other tolerances and ranks to see how the approximation quality changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine a truncation rank.\n",
    "tol = 1e-06\n",
    "r   = np.count_nonzero(s1 > s1[0] * tol)\n",
    "print(f\"Reduced dimension: {r}\")\n",
    "\n",
    "# Compute the reduced-order system.\n",
    "Ar = Phi_2[:, :r].T @ (AL.real @ Psi_1T[:r, :].T)\n",
    "br = Phi_2[:, :r].T @ bL.real\n",
    "cr = cL.real @ Psi_1T[:r, :].T\n",
    "Er = Phi_2[:, :r].T @ (EL.real @ Psi_1T[:r, :].T)\n",
    "\n",
    "# Define the ROM.\n",
    "loewner_rom = utils.SISO(A = Ar, b = br, c = cr, E = Er)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we check the quality of our approximation with respect to the given data. Since in most applications, only data is given rather than the actual system, this is the more practical approach for checking performance. In this sense, it is not uncommon to go back and choose a larger rank if the approximation quality appears to be insufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency response of the approximation in the given data points.\n",
    "rom_responses = loewner_rom.transfer_function(1j * training_frequencies)\n",
    "\n",
    "rom_relative_error = np.abs(rom_responses - training_responses) / np.abs(\n",
    "    training_responses\n",
    ")\n",
    "\n",
    "axes = utils.plot_comparison(\n",
    "    training_frequencies, training_responses, rom_responses, rom_relative_error\n",
    ")\n",
    "axes[0].legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the tutorial example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
